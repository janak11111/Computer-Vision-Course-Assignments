# -*- coding: utf-8 -*-
"""CV_A4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wQOkkNj-rlC_o6DN_P-yT2s-rea2Z2aC

## **CV HW4: Multi-object Tracking (MOT) with Detection**
**Detection**: YOLOv5, 
**Tracking**: Simple Online Realtime Tracking (SORT)

---

## **1. Unzip data folder**
"""

# Change the path according to your setup 
!unzip '/content/sort-master.zip'
!unzip '/content/KITTI_17_images.zip'

"""# **2. Install requirements**"""

!pip install -r sort-master/requirements.txt
!pip install cv

"""# **3. Import libraries**"""

import torch
import torchvision
import cv2
import sys
import matplotlib
from google.colab.patches import cv2_imshow
from collections import namedtuple, OrderedDict
sys.path.insert(0, './sort-master/')

"""# **4. Load YOLOv5 detector from torch hub**"""

yolov5_detector = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained = True)
yolov5_detector.float()
yolov5_detector.eval()

"""# **5. Import SORT library**"""

!pip install filterpy
from sort import *

"""#**6. Perform tracking with detection**"""

# Write your code here to perform tracking with detection using the provided YOLOv5 model and the SORT implementation
import os
import glob


# create object of tracker
tracker_obj = Sort()

# load the path
images_path = sorted(glob.glob('/content/KITTI_17_images/*'))
output_dir = '/content/result_img/'
result_file = '/content/results.txt'
objects = {}



for i, image in enumerate(images_path):
  img = cv2.imread(image)
  results = yolov5_detector(img)
  boxes = results.xyxy[0].cpu().numpy()
  class_ids = results.xyxy[0][:, -1].cpu().numpy().astype(int)

  person_mask = class_ids == 0
  person_bbox = boxes[person_mask]
  person_tracks = tracker_obj.update(person_bbox)

  for track in person_tracks:
    track_id = int(track[4])
    b_box = track[:4].astype(float)
    conf_score = results.xyxy[0][:, 4].cpu().numpy()
    cv2.rectangle(img, (int(b_box[0]), int(b_box[1])), (int(b_box[2]), int(b_box[3])), (0, 255, 0), 2)
    cv2.putText(img, str(track_id), (int(b_box[0]), int(b_box[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    if track_id in objects:
        objects[track_id]['boxes'].append(b_box)
    else:
        objects[track_id] = {'boxes': [b_box]}

  for track_id in list(objects.keys()):
    results_str = ','.join([str(i+1)]+[str(track_id)] + [str(round(coord,2)) for bbox in objects[track_id]['boxes'] for coord in bbox] +[str(round(conf_score[4]))]+ ['-1'] * 3)
    with open(result_file, 'a') as f:
        f.write(results_str + '\n')
    objects.pop(track_id)


  output_path = os.path.join(output_dir, 'output_{}.jpg'.format(i+1))
  cv2.imwrite(output_path, img)
  cv2_imshow(img)



# Set the path where the frames is located
folder_path = '/content/result_img'

# Get the list of file names in the folder and sort them
file_names = os.listdir(folder_path)
file_names.sort()

# Set the output video filename, codec, frames per second, and size
output_filename = 'video.mp4'
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
fps = 10
size = (1234, 370)

# Create a VideoWriter object to write the frames to the output video
out = cv2.VideoWriter(output_filename, fourcc, fps, size)

# Loop through the list of file names, read each image, resize it, and write it to the output video
for file_name in file_names:
    img_path = os.path.join(folder_path, file_name)
    img = cv2.imread(img_path)
    img = cv2.resize(img, size)
    out.write(img)

"""# **7. Report Evaluation Metrics**"""

# Use the Track-Eval kit to report the complete set of performance and accuracy metrics
# Comment on and interpret MOTA and MOTP values
!unzip "/content/TrackEval-master.zip"

